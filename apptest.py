"""
äº¤æ˜“æ•¸æ“šåˆ†æç³»çµ± (Trading Analysis System)
æ”¯æŒå¤§è¦æ¨¡äº¤æ˜“æ•¸æ“šï¼ˆåè¬ç­†ä»¥ä¸Šï¼‰çš„è™•ç†èˆ‡åˆ†æ

ç¬¬ä¸€éšæ®µé‡æ§‹ï¼šæ•´åˆæ ¸å¿ƒæ•¸æ“šå¼•æ“
- é«˜æ•ˆå¿«å–æ©Ÿåˆ¶
- å‘é‡åŒ–é‹ç®—ï¼ˆç¦æ­¢ apply/loopï¼‰
- AID å¼·åˆ¶å­—ä¸²åŒ–ï¼ˆè§£æ±ºè¤‡è£½å¤±æ•ˆï¼‰
- å¤§æ•¸æ“šæ¡æ¨£å„ªåŒ–
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from io import BytesIO
from typing import Tuple, Optional, Dict, Any

# ==================== é é¢é…ç½® ====================
st.set_page_config(
    page_title="äº¤æ˜“æ•¸æ“šåˆ†æç³»çµ±",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== æ¬„ä½æ˜ å°„é…ç½® ====================
COLUMN_MAP = {
    'execution_time': 'Execution Time\näº¤æ˜“æ—¶é—´',
    'open_time': 'Open Time\nå¼€ä»“æ—¶é—´',
    'aid': 'AID\nç”¨æˆ·è´¦å·',
    'closed_pl': 'Closed P/L\nå¹³ä»“ç›ˆäº',
    'commission': 'Commission\næ‰‹ç»­è´¹',
    'swap': 'Swap\néš”å¤œåˆ©æ¯',
    'instrument': 'Instrument\näº¤æ˜“å“ç§',
    'business_type': 'Business Type\nä¸šåŠ¡ç±»å‹',
    'action': 'Action\näº¤æ˜“ç±»å‹',
    'volume': 'Volume\nå¼€ä»“æ•°é‡',
    'side': 'Side\näº¤æ˜“æ–¹å‘'
}


# ==================== æ ¸å¿ƒæ•¸æ“šå¼•æ“ï¼ˆç¬¬ä¸€éšæ®µé‡æ§‹ï¼‰====================

@st.cache_data(show_spinner=False, ttl=3600)
def load_data(uploaded_files) -> Optional[pd.DataFrame]:
    """
    é«˜æ•ˆè¼‰å…¥ä¸¦é è™•ç†äº¤æ˜“æ•¸æ“š
    
    ç‰¹æ€§ï¼š
    - ä½¿ç”¨ @st.cache_data å¿«å–ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    - æ”¯æŒå¤šæª”æ¡ˆåˆä½µ
    - å¼·åˆ¶ AID ç‚ºå­—ä¸²é¡å‹ï¼ˆè§£æ±ºè¤‡è£½å•é¡Œï¼‰
    - å‘é‡åŒ–æ™‚é–“èˆ‡ç›ˆè™§è¨ˆç®—
    """
    if not uploaded_files:
        return None
    
    dfs = []
    
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, dtype={COLUMN_MAP['aid']: str})
            else:
                df = pd.read_excel(uploaded_file, dtype={COLUMN_MAP['aid']: str})
            dfs.append(df)
        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    if not dfs:
        return None
    
    # å‘é‡åŒ–åˆä½µæ‰€æœ‰æ•¸æ“š
    df = pd.concat(dfs, ignore_index=True)
    
    # æ•¸æ“šæ¸…æ´—æµç¨‹
    df = _clean_data(df)
    
    return df


def _clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ•¸æ“šæ¸…æ´—ï¼ˆå…§éƒ¨å‡½æ•¸ï¼‰
    
    åŸ·è¡Œé †åºï¼š
    1. ç§»é™¤ Total è¡Œ
    2. å»é‡
    3. å¼·åˆ¶ AID ç‚ºå­—ä¸²ï¼ˆé—œéµï¼è§£æ±ºè¤‡è£½å¤±æ•ˆå•é¡Œï¼‰
    4. è½‰æ›æ™‚é–“æ¬„ä½
    5. å¡«å……ç©ºå€¼
    6. è¨ˆç®— Net_PL å’Œ Hold_Seconds
    """
    exec_col = COLUMN_MAP['execution_time']
    aid_col = COLUMN_MAP['aid']
    
    # 1. ç§»é™¤ Total è¡Œ
    if exec_col in df.columns:
        df = df[df[exec_col] != 'Total'].copy()
    
    # 2. å»é‡
    df = df.drop_duplicates()
    
    # 3. ã€é—œéµã€‘å¼·åˆ¶ AID ç‚ºå­—ä¸²é¡å‹ï¼Œç§»é™¤æµ®é»æ•¸ .0 å¾Œç¶´
    if aid_col in df.columns:
        df[aid_col] = (
            df[aid_col]
            .astype(str)
            .str.replace(r'\.0$', '', regex=True)
            .str.strip()
        )
    
    # 4. å‘é‡åŒ–è½‰æ›æ™‚é–“æ¬„ä½
    for col_key in ['execution_time', 'open_time']:
        col_name = COLUMN_MAP[col_key]
        if col_name in df.columns:
            df[col_name] = pd.to_datetime(df[col_name], errors='coerce')
    
    # 5. å‘é‡åŒ–å¡«å……ç©ºå€¼ï¼ˆç›ˆè™§èˆ‡è²»ç”¨ï¼‰
    numeric_cols = ['closed_pl', 'commission', 'swap']
    for col_key in numeric_cols:
        col_name = COLUMN_MAP[col_key]
        if col_name in df.columns:
            df[col_name] = pd.to_numeric(df[col_name], errors='coerce').fillna(0)
    
    # 6. å‘é‡åŒ–è¨ˆç®— Net_PL
    df['Net_PL'] = (
        df[COLUMN_MAP['closed_pl']] + 
        df[COLUMN_MAP['commission']] + 
        df[COLUMN_MAP['swap']]
    )
    
    # 7. å‘é‡åŒ–è¨ˆç®— Hold_Seconds
    exec_time = df[COLUMN_MAP['execution_time']]
    open_time = df[COLUMN_MAP['open_time']]
    
    valid_mask = pd.notna(exec_time) & pd.notna(open_time)
    df['Hold_Seconds'] = np.where(
        valid_mask,
        (exec_time - open_time).dt.total_seconds(),
        np.nan
    )
    
    return df


def filter_closing_trades(df: pd.DataFrame) -> pd.DataFrame:
    """ç¯©é¸å·²å¹³å€‰äº¤æ˜“ï¼ˆCLOSINGï¼‰"""
    action_col = COLUMN_MAP['action']
    if action_col in df.columns:
        return df[df[action_col] == 'CLOSING'].copy()
    return df.copy()


@st.cache_data(show_spinner=False)
def get_client_metrics(
    df: pd.DataFrame, 
    initial_balance: float = 10000,
    scalper_threshold_seconds: int = 300
) -> pd.DataFrame:
    """
    å‘é‡åŒ–è¨ˆç®—å®¢æˆ¶æŒ‡æ¨™ï¼ˆç¦æ­¢ apply/loopï¼‰
    
    è¨ˆç®—æŒ‡æ¨™ï¼š
    - Total_PL, Scalp_PL, Scalp_Pct, Win_Rate
    - Sharpe_Ratio, MDD_Pct, PL_Q1, PL_Median, PL_Q3
    """
    aid_col = COLUMN_MAP['aid']
    
    # ç¢ºä¿ AID ç‚ºå­—ä¸²
    df = df.copy()
    df[aid_col] = df[aid_col].astype(str)
    
    # ç¯©é¸å¹³å€‰äº¤æ˜“
    closing_df = filter_closing_trades(df)
    
    if closing_df.empty:
        return pd.DataFrame()
    
    # ========== åŸºç¤èšåˆï¼ˆå‘é‡åŒ– groupbyï¼‰==========
    basic_stats = closing_df.groupby(aid_col, as_index=False).agg(
        Total_PL=('Net_PL', 'sum'),
        Trade_Count=('Net_PL', 'count'),
        Avg_PL=('Net_PL', 'mean'),
        Std_PL=('Net_PL', 'std')
    )
    
    # å‹ç‡è¨ˆç®—
    closing_df = closing_df.copy()
    closing_df['_is_win'] = (closing_df['Net_PL'] > 0).astype(int)
    win_stats = closing_df.groupby(aid_col, as_index=False).agg(
        Win_Count=('_is_win', 'sum')
    )
    
    metrics = basic_stats.merge(win_stats, on=aid_col, how='left')
    metrics['Win_Rate'] = (metrics['Win_Count'] / metrics['Trade_Count'] * 100).round(2)
    
    # Sharpe Ratio
    metrics['Sharpe_Ratio'] = np.where(
        metrics['Std_PL'] > 0,
        (metrics['Avg_PL'] / metrics['Std_PL']).round(4),
        0
    )
    
    # åˆ†ä½æ•¸
    quantile_stats = closing_df.groupby(aid_col)['Net_PL'].quantile([0.25, 0.5, 0.75]).unstack()
    quantile_stats.columns = ['PL_Q1', 'PL_Median', 'PL_Q3']
    quantile_stats = quantile_stats.reset_index()
    metrics = metrics.merge(quantile_stats, on=aid_col, how='left')
    
    # ========== Scalp ç›¸é—œæŒ‡æ¨™ ==========
    scalp_df = closing_df[closing_df['Hold_Seconds'] < scalper_threshold_seconds]
    if not scalp_df.empty:
        scalp_agg = scalp_df.groupby(aid_col, as_index=False).agg(
            Scalp_Count=('Net_PL', 'count'),
            Scalp_PL=('Net_PL', 'sum')
        )
        metrics = metrics.merge(scalp_agg, on=aid_col, how='left')
    
    metrics['Scalp_Count'] = metrics.get('Scalp_Count', 0).fillna(0).astype(int)
    metrics['Scalp_PL'] = metrics.get('Scalp_PL', 0).fillna(0)
    metrics['Scalp_Pct'] = (metrics['Scalp_Count'] / metrics['Trade_Count'] * 100).round(2)
    
    # ========== MDD% è¨ˆç®— ==========
    mdd_series = _calculate_mdd_vectorized(closing_df, aid_col, initial_balance)
    mdd_df = mdd_series.reset_index()
    mdd_df.columns = [aid_col, 'MDD_Pct']
    metrics = metrics.merge(mdd_df, on=aid_col, how='left')
    metrics['MDD_Pct'] = metrics['MDD_Pct'].fillna(0)
    
    # å¼·åˆ¶ AID ç‚ºå­—ä¸²
    metrics[aid_col] = metrics[aid_col].astype(str)
    
    output_cols = [
        aid_col, 'Total_PL', 'Scalp_PL', 'Scalp_Pct', 
        'Win_Rate', 'Sharpe_Ratio', 'MDD_Pct',
        'PL_Q1', 'PL_Median', 'PL_Q3', 'Trade_Count'
    ]
    
    for col in output_cols:
        if col not in metrics.columns:
            metrics[col] = 0
    
    return metrics[output_cols].round(2)


def _calculate_mdd_vectorized(
    df: pd.DataFrame, 
    aid_col: str, 
    initial_balance: float
) -> pd.Series:
    """å‘é‡åŒ–è¨ˆç®—æ¯å€‹å®¢æˆ¶çš„ MDD%"""
    exec_col = COLUMN_MAP['execution_time']
    
    df_sorted = df.sort_values([aid_col, exec_col]).copy()
    df_sorted['_cumsum'] = df_sorted.groupby(aid_col)['Net_PL'].cumsum()
    df_sorted['_equity'] = initial_balance + df_sorted['_cumsum']
    df_sorted['_running_max'] = df_sorted.groupby(aid_col)['_equity'].cummax()
    
    df_sorted['_drawdown'] = np.where(
        df_sorted['_running_max'] != 0,
        (df_sorted['_equity'] - df_sorted['_running_max']) / df_sorted['_running_max'],
        0
    )
    
    mdd_series = df_sorted.groupby(aid_col)['_drawdown'].min().abs() * 100
    return mdd_series.round(2)


@st.cache_data(show_spinner=False)
def get_client_summary_for_violin(
    df: pd.DataFrame,
    max_clients: int = 5000,
    sample_rate: float = 0.1
) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    ç‚º Violin Plot æº–å‚™å®¢æˆ¶å±¤ç´šæ‘˜è¦æ•¸æ“šï¼ˆå«æ¡æ¨£ï¼‰
    """
    aid_col = COLUMN_MAP['aid']
    
    df = df.copy()
    df[aid_col] = df[aid_col].astype(str)
    
    # å‘é‡åŒ–è¨ˆç®—æ¯ä½å®¢æˆ¶çš„ç´¯è¨ˆç›ˆè™§
    client_pl = df.groupby(aid_col, as_index=False)['Net_PL'].sum()
    client_pl.columns = ['AID', 'ç´¯è¨ˆæ·¨ç›ˆè™§']
    
    # å¼·åˆ¶ AID ç‚ºå­—ä¸²
    client_pl['AID'] = client_pl['AID'].astype(str)
    
    n_clients = len(client_pl)
    
    sampling_info = {
        'original_count': n_clients,
        'sampled': False,
        'sampled_count': n_clients,
        'sample_rate': 1.0
    }
    
    if n_clients <= max_clients:
        return client_pl, sampling_info
    
    # æ¡æ¨£
    sampled_clients = client_pl.sample(frac=sample_rate, random_state=42)
    
    sampling_info.update({
        'sampled': True,
        'sampled_count': len(sampled_clients),
        'sample_rate': sample_rate
    })
    
    return sampled_clients, sampling_info


# ==================== MDD è¨ˆç®—å‡½æ•¸ï¼ˆå‘é‡åŒ–ç‰ˆæœ¬ï¼‰====================

def calculate_mdd(equity_series, initial_balance=0):
    """è¨ˆç®—æœ€å¤§å›æ’¤ (Maximum Drawdown)"""
    if len(equity_series) < 2:
        return 0.0, pd.Series([0.0])
    
    cumulative_equity = initial_balance + equity_series.cumsum()
    running_max = cumulative_equity.cummax()
    
    drawdown = np.where(
        running_max != 0,
        (cumulative_equity - running_max) / running_max,
        0
    )
    
    mdd = np.min(drawdown)
    return mdd, pd.Series(drawdown, index=equity_series.index)


# ==================== ç•¶æ—¥åˆ†æå‡½æ•¸ ====================

def get_daily_analysis(df, scalper_threshold_seconds=300):
    """å–å¾—ç•¶æ—¥åˆ†ææ•¸æ“šï¼ˆå‘é‡åŒ–å„ªåŒ–ï¼‰"""
    exec_col = COLUMN_MAP['execution_time']
    aid_col = COLUMN_MAP['aid']
    instrument_col = COLUMN_MAP['instrument']
    
    closing_df = filter_closing_trades(df)
    
    if closing_df.empty:
        return None, None
    
    # æ‰¾å‡ºæœ€æ–°æ—¥æœŸä½œç‚ºã€Œç•¶æ—¥ã€
    latest_date = closing_df[exec_col].max().date()
    daily_df = closing_df[closing_df[exec_col].dt.date == latest_date].copy()
    
    if daily_df.empty:
        return None, None
    
    # Top 10 Profit å®¢æˆ¶ï¼ˆå‘é‡åŒ–ï¼‰
    top_profit = daily_df.groupby(aid_col, as_index=False).agg(
        ç•¶æ—¥ç¸½ç›ˆè™§=('Net_PL', 'sum')
    )
    top_profit = top_profit.nlargest(10, 'ç•¶æ—¥ç¸½ç›ˆè™§')
    top_profit.columns = ['AID', 'ç•¶æ—¥ç¸½ç›ˆè™§']
    top_profit['AID'] = top_profit['AID'].astype(str)
    
    # Top 10 Scalpersï¼ˆå‘é‡åŒ–ï¼‰
    scalp_df = daily_df[daily_df['Hold_Seconds'] < scalper_threshold_seconds].copy()
    
    if not scalp_df.empty:
        # å‘é‡åŒ–èšåˆ
        scalper_stats = scalp_df.groupby(aid_col, as_index=False).agg(
            äº¤æ˜“ç­†æ•¸=('Net_PL', 'count'),
            ç•¶æ—¥ç¸½ç›ˆè™§=('Net_PL', 'sum'),
            å¹³å‡å–®ç­†ç›ˆè™§=('Net_PL', 'mean'),
            å¹³å‡æŒå€‰ç§’æ•¸=('Hold_Seconds', 'mean')
        )
        
        # è¨ˆç®—å‹ç‡ï¼ˆå‘é‡åŒ–ï¼‰
        scalp_df['_is_win'] = (scalp_df['Net_PL'] > 0).astype(int)
        win_rate_df = scalp_df.groupby(aid_col, as_index=False).agg(
            _wins=('_is_win', 'sum'),
            _total=('_is_win', 'count')
        )
        win_rate_df['å‹ç‡(%)'] = (win_rate_df['_wins'] / win_rate_df['_total'] * 100).round(2)
        
        scalper_stats = scalper_stats.merge(win_rate_df[[aid_col, 'å‹ç‡(%)']], on=aid_col, how='left')
        
        # ä¸»è¦äº¤æ˜“å“ç¨®ï¼ˆä½¿ç”¨ transform + mode å‘é‡åŒ–æ›¿ä»£ï¼‰
        if instrument_col in scalp_df.columns:
            mode_df = scalp_df.groupby(aid_col)[instrument_col].agg(
                lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'N/A'
            ).reset_index()
            mode_df.columns = [aid_col, 'ä¸»è¦äº¤æ˜“å“ç¨®']
            scalper_stats = scalper_stats.merge(mode_df, on=aid_col, how='left')
        else:
            scalper_stats['ä¸»è¦äº¤æ˜“å“ç¨®'] = 'N/A'
        
        # å–äº¤æ˜“ç­†æ•¸æœ€å¤šçš„å‰ 10 å
        top_scalpers = scalper_stats.nlargest(10, 'äº¤æ˜“ç­†æ•¸')
        top_scalpers = top_scalpers[[aid_col, 'äº¤æ˜“ç­†æ•¸', 'å¹³å‡æŒå€‰ç§’æ•¸', 'ç•¶æ—¥ç¸½ç›ˆè™§', 'å‹ç‡(%)', 'ä¸»è¦äº¤æ˜“å“ç¨®']]
        top_scalpers.columns = ['AID', 'äº¤æ˜“ç­†æ•¸', 'å¹³å‡æŒå€‰ç§’æ•¸', 'ç•¶æ—¥ç¸½ç›ˆè™§', 'å‹ç‡(%)', 'ä¸»è¦äº¤æ˜“å“ç¨®']
        top_scalpers['AID'] = top_scalpers['AID'].astype(str)
        top_scalpers['å¹³å‡æŒå€‰ç§’æ•¸'] = top_scalpers['å¹³å‡æŒå€‰ç§’æ•¸'].round(1)
    else:
        top_scalpers = pd.DataFrame()
    
    return top_profit, top_scalpers, latest_date


# ==================== 30å¤©åˆ†æå‡½æ•¸ ====================

def get_30day_analysis(df):
    """å–å¾—30å¤©åˆ†ææ•¸æ“š"""
    exec_col = COLUMN_MAP['execution_time']
    
    closing_df = filter_closing_trades(df)
    
    if closing_df.empty:
        return None
    
    latest_date = closing_df[exec_col].max()
    start_date = latest_date - timedelta(days=30)
    
    df_30d = closing_df[closing_df[exec_col] >= start_date].copy()
    
    return df_30d, start_date, latest_date


# ==================== åœ–è¡¨å‡½æ•¸ï¼ˆå‘é‡åŒ–å„ªåŒ–ï¼‰====================

def create_cumulative_pnl_chart(df, initial_balance=0, scalper_threshold_seconds=300):
    """å‰µå»ºç´¯è¨ˆæ·¨ç›ˆè™§èµ°å‹¢åœ–ï¼šæ•´é«” vs. Scalper"""
    exec_col = COLUMN_MAP['execution_time']
    scalper_minutes = scalper_threshold_seconds / 60
    
    df_sorted = df.sort_values(exec_col).copy()
    df_sorted['Date'] = df_sorted[exec_col].dt.date
    
    # å‘é‡åŒ–è¨ˆç®—æ¯æ—¥ç›ˆè™§
    daily_pnl = df_sorted.groupby('Date', as_index=False)['Net_PL'].sum()
    daily_pnl.columns = ['Date', 'Daily_PL']
    daily_pnl = daily_pnl.sort_values('Date')
    daily_pnl['Cumulative_PL'] = initial_balance + daily_pnl['Daily_PL'].cumsum()
    
    # Scalper æ¯æ—¥ç›ˆè™§
    scalper_df = df_sorted[df_sorted['Hold_Seconds'] < scalper_threshold_seconds]
    
    if not scalper_df.empty:
        scalper_daily_pnl = scalper_df.groupby('Date', as_index=False)['Net_PL'].sum()
        scalper_daily_pnl.columns = ['Date', 'Scalper_Daily_PL']
    else:
        scalper_daily_pnl = pd.DataFrame({'Date': daily_pnl['Date'], 'Scalper_Daily_PL': 0})
    
    merged_df = daily_pnl.merge(scalper_daily_pnl, on='Date', how='left')
    merged_df['Scalper_Daily_PL'] = merged_df['Scalper_Daily_PL'].fillna(0)
    merged_df['Scalper_Cumulative_PL'] = initial_balance + merged_df['Scalper_Daily_PL'].cumsum()
    merged_df['Date'] = pd.to_datetime(merged_df['Date'])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=merged_df['Date'],
        y=merged_df['Cumulative_PL'],
        mode='lines+markers',
        name='æ•´é«”ç´¯è¨ˆç›ˆè™§',
        line=dict(color='#2E86AB', width=2.5),
        marker=dict(size=6),
        hovertemplate='<b>æ—¥æœŸ:</b> %{x|%Y-%m-%d}<br><b>æ•´é«”ç´¯è¨ˆ:</b> $%{y:,.2f}<extra></extra>'
    ))
    
    fig.add_trace(go.Scatter(
        x=merged_df['Date'],
        y=merged_df['Scalper_Cumulative_PL'],
        mode='lines+markers',
        name=f'Scalper ç´¯è¨ˆç›ˆè™§ (<{scalper_minutes:.0f}åˆ†é˜)',
        line=dict(color='#F39C12', width=2.5, dash='dot'),
        marker=dict(size=6, symbol='diamond'),
        hovertemplate='<b>æ—¥æœŸ:</b> %{x|%Y-%m-%d}<br><b>Scalper ç´¯è¨ˆ:</b> $%{y:,.2f}<extra></extra>'
    ))
    
    fig.add_hline(
        y=initial_balance, 
        line_dash="dash", 
        line_color="gray", 
        line_width=1.5,
        annotation_text=f"åˆå§‹è³‡é‡‘: ${initial_balance:,}",
        annotation_position="right"
    )
    
    fig.update_layout(
        title=dict(
            text=f'ğŸ“ˆ ç´¯è¨ˆæ·¨ç›ˆè™§èµ°å‹¢ï¼šæ•´é«” vs. Scalper (åˆå§‹è³‡é‡‘: ${initial_balance:,})',
            font=dict(size=16)
        ),
        xaxis_title='æ—¥æœŸ',
        yaxis_title='ç´¯è¨ˆæ·¨ç›ˆè™§ ($)',
        height=500,
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        hovermode='x unified',
        plot_bgcolor='rgba(248,249,250,1)'
    )
    
    total_pnl = merged_df['Cumulative_PL'].iloc[-1] - initial_balance
    scalper_pnl = merged_df['Scalper_Cumulative_PL'].iloc[-1] - initial_balance
    scalper_ratio = (scalper_pnl / total_pnl * 100) if total_pnl != 0 else 0
    
    stats = {
        'total_pnl': total_pnl,
        'scalper_pnl': scalper_pnl,
        'scalper_ratio': scalper_ratio,
        'non_scalper_pnl': total_pnl - scalper_pnl
    }
    
    return fig, stats


def create_violin_plot(df, filter_extreme=True, max_clients=5000, sample_rate=0.1):
    """
    å‰µå»ºå°æç´åœ– (Violin Plot) ä¸¦å…§åµŒ Box
    
    é‡æ§‹ï¼šä½¿ç”¨æ¡æ¨£æ©Ÿåˆ¶å„ªåŒ–å¤§æ•¸æ“šæ¸²æŸ“
    """
    aid_col = COLUMN_MAP['aid']
    
    # ä½¿ç”¨å‘é‡åŒ–çš„å®¢æˆ¶æ‘˜è¦å‡½æ•¸ï¼ˆå«æ¡æ¨£ï¼‰
    aid_pl, sampling_info = get_client_summary_for_violin(df, max_clients, sample_rate)
    
    # è¨ˆç®— 1% å’Œ 99% ç™¾åˆ†ä½æ•¸
    Q1_percentile = aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.01)
    Q99_percentile = aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.99)
    
    # æ ¹æ“šé¸é …æ±ºå®šæ˜¯å¦éæ¿¾æ¥µç«¯å€¼
    if filter_extreme:
        plot_data = aid_pl[
            (aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'] >= Q1_percentile) & 
            (aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'] <= Q99_percentile)
        ].copy()
        title_suffix = "(å·²éæ¿¾æ¥µç«¯å€¼: 1%-99% å€é–“)"
        filtered_count = len(aid_pl) - len(plot_data)
    else:
        plot_data = aid_pl.copy()
        title_suffix = "(åŸå§‹æ•¸æ“š)"
        filtered_count = 0
    
    # æ·»åŠ æ¡æ¨£è³‡è¨Šåˆ°æ¨™é¡Œ
    if sampling_info['sampled']:
        title_suffix += f" [å·²æ¡æ¨£ {sampling_info['sample_rate']*100:.0f}%]"
    
    # è¨ˆç®— IQR å’Œç•°å¸¸å€¼é‚Šç•Œ
    Q1 = aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.25)
    Q3 = aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = aid_pl[(aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'] < lower_bound) | (aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'] > upper_bound)]
    
    mean_val = plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'].mean()
    median_val = plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'].median()
    std_val = plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'].std()
    
    y_lower = plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.05)
    y_upper = plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'].quantile(0.95)
    y_padding = (y_upper - y_lower) * 0.15
    y_range = [y_lower - y_padding, y_upper + y_padding]
    
    fig = go.Figure()
    
    fig.add_trace(go.Violin(
        y=plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'],
        name='ç›ˆè™§åˆ†å¸ƒ',
        box_visible=True,
        meanline_visible=True,
        line_color='#2C3E50',
        fillcolor='rgba(52, 152, 219, 0.5)',
        opacity=0.8,
        points='all',
        pointpos=-0.8,
        jitter=0.3,
        marker=dict(color='#3498DB', size=5, opacity=0.5, line=dict(width=0.5, color='#2C3E50')),
        box=dict(visible=True, fillcolor='rgba(255, 255, 255, 0.8)', line=dict(color='#2C3E50', width=2)),
        meanline=dict(visible=True, color='#E74C3C', width=2),
        hoverinfo='y',
        customdata=plot_data['AID'].values,
        hovertemplate='<b>ç´¯è¨ˆæ·¨ç›ˆè™§:</b> $%{y:,.2f}<extra></extra>'
    ))
    
    fig.add_trace(go.Scatter(
        x=[0] * len(plot_data),
        y=plot_data['ç´¯è¨ˆæ·¨ç›ˆè™§'],
        mode='markers',
        marker=dict(color='rgba(0,0,0,0)', size=10),
        customdata=plot_data['AID'].values,
        hovertemplate='<b>AID:</b> %{customdata}<br><b>ç´¯è¨ˆæ·¨ç›ˆè™§:</b> $%{y:,.2f}<extra></extra>',
        showlegend=False
    ))
    
    fig.update_layout(
        title=dict(text=f'ğŸ» å®¢æˆ¶ç›ˆè™§åˆ†å¸ƒåœ– (Violin Plot) {title_suffix}', font=dict(size=18)),
        height=700,
        yaxis=dict(title='ç´¯è¨ˆæ·¨ç›ˆè™§ ($)', range=y_range, zeroline=True, zerolinecolor='rgba(0,0,0,0.3)', zerolinewidth=2, gridcolor='rgba(0,0,0,0.1)'),
        xaxis=dict(showticklabels=False, showgrid=False),
        showlegend=False,
        plot_bgcolor='rgba(248,249,250,1)',
        annotations=[
            dict(
                x=0.02, y=0.98, xref='paper', yref='paper',
                text=f'<b>ğŸ“Š çµ±è¨ˆæ‘˜è¦</b><br>â”â”â”â”â”â”â”â”â”â”â”<br>å®¢æˆ¶æ•¸: {len(plot_data):,}<br>å¹³å‡å€¼: ${mean_val:,.2f}<br>ä¸­ä½æ•¸: ${median_val:,.2f}<br>æ¨™æº–å·®: ${std_val:,.2f}<br>â”â”â”â”â”â”â”â”â”â”â”<br>Q25: ${plot_data["ç´¯è¨ˆæ·¨ç›ˆè™§"].quantile(0.25):,.2f}<br>Q75: ${plot_data["ç´¯è¨ˆæ·¨ç›ˆè™§"].quantile(0.75):,.2f}',
                showarrow=False, font=dict(size=11, family='monospace'), align='left',
                bgcolor='rgba(255,255,255,0.95)', bordercolor='#3498DB', borderwidth=2, borderpad=8
            ),
            dict(
                x=0.98, y=0.98, xref='paper', yref='paper',
                text='<b>ğŸ“– åœ–ä¾‹èªªæ˜</b><br>â”â”â”â”â”â”â”â”â”â”â”<br>ğŸ”´ ç´…ç·š = å¹³å‡å€¼<br>â¬œ ç™½æ¡† = IQR (Q25-Q75)<br>ğŸ”µ è—é» = å€‹åˆ¥å®¢æˆ¶<br>ğŸ» å¯¬åº¦ = å¯†åº¦åˆ†å¸ƒ',
                showarrow=False, font=dict(size=10, family='monospace'), align='left',
                bgcolor='rgba(255,255,255,0.95)', bordercolor='#95a5a6', borderwidth=1, borderpad=8
            )
        ]
    )
    
    if y_range[0] <= 0 <= y_range[1]:
        fig.add_hline(y=0, line_dash="solid", line_color="rgba(0,0,0,0.5)", line_width=2,
                      annotation_text="æç›Šå¹³è¡¡ç·š", annotation_position="right", annotation_font=dict(size=10, color='gray'))
    
    pos_outliers = outliers[outliers['ç´¯è¨ˆæ·¨ç›ˆè™§'] > upper_bound].nlargest(5, 'ç´¯è¨ˆæ·¨ç›ˆè™§')
    neg_outliers = outliers[outliers['ç´¯è¨ˆæ·¨ç›ˆè™§'] < lower_bound].nsmallest(5, 'ç´¯è¨ˆæ·¨ç›ˆè™§')
    
    mean_pl = aid_pl['ç´¯è¨ˆæ·¨ç›ˆè™§'].mean()
    if not pos_outliers.empty:
        pos_outliers = pos_outliers.copy()
        pos_outliers['åé›¢å¹³å‡å€¼'] = pos_outliers['ç´¯è¨ˆæ·¨ç›ˆè™§'] - mean_pl
    if not neg_outliers.empty:
        neg_outliers = neg_outliers.copy()
        neg_outliers['åé›¢å¹³å‡å€¼'] = neg_outliers['ç´¯è¨ˆæ·¨ç›ˆè™§'] - mean_pl
    
    filter_info = {
        'Q1_percentile': Q1_percentile,
        'Q99_percentile': Q99_percentile,
        'filtered_count': filtered_count,
        'total_count': sampling_info['original_count'],
        'y_range': y_range,
        'sampling_info': sampling_info
    }
    
    return fig, pos_outliers, neg_outliers, filter_info


def create_profit_factor_chart(df):
    """
    å‰µå»ºç²åˆ©å› å­åˆ†å¸ƒåœ–ï¼ˆå‘é‡åŒ–é‡æ§‹ï¼‰
    
    ä½¿ç”¨ç´”å‘é‡åŒ–é‹ç®—æ›¿ä»£ apply
    """
    aid_col = COLUMN_MAP['aid']
    closed_pl_col = COLUMN_MAP['closed_pl']
    
    df = df.copy()
    df[aid_col] = df[aid_col].astype(str)
    
    # å‘é‡åŒ–è¨ˆç®—ï¼šåˆ†åˆ¥èšåˆç›ˆåˆ©å’Œè™§æ
    df['_gain'] = np.where(df[closed_pl_col] > 0, df[closed_pl_col], 0)
    df['_loss'] = np.where(df[closed_pl_col] < 0, np.abs(df[closed_pl_col]), 0)
    
    pf_agg = df.groupby(aid_col, as_index=False).agg(
        Total_Gain=('_gain', 'sum'),
        Total_Loss=('_loss', 'sum')
    )
    
    # å‘é‡åŒ–è¨ˆç®— Profit Factor
    pf_agg['Profit_Factor'] = np.where(
        pf_agg['Total_Loss'] == 0,
        np.where(pf_agg['Total_Gain'] > 0, 5.0, 0.0),
        pf_agg['Total_Gain'] / pf_agg['Total_Loss']
    )
    
    pf_data = pf_agg[[aid_col, 'Profit_Factor']].copy()
    pf_data.columns = ['AID', 'Profit_Factor']
    pf_data['AID'] = pf_data['AID'].astype(str)
    
    # å®šç¾© PF å€é–“
    bins = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 5.0, float('inf')]
    labels = ['0-0.5', '0.5-1.0', '1.0-1.5', '1.5-2.0', '2.0-2.5', '2.5-3.0', '3.0-5.0', '5.0+']
    pf_data['PF_Range'] = pd.cut(pf_data['Profit_Factor'], bins=bins, labels=labels, right=False)
    
    pf_dist = pf_data['PF_Range'].value_counts().sort_index().reset_index()
    pf_dist.columns = ['PFå€é–“', 'äº¤æ˜“è€…æ•¸é‡']
    
    fig = go.Figure()
    colors = ['#E74C3C', '#E74C3C', '#27AE60', '#27AE60', '#27AE60', '#27AE60', '#27AE60', '#27AE60']
    
    fig.add_trace(go.Bar(
        x=pf_dist['PFå€é–“'],
        y=pf_dist['äº¤æ˜“è€…æ•¸é‡'],
        marker_color=colors[:len(pf_dist)],
        name='äº¤æ˜“è€…æ•¸é‡'
    ))
    
    fig.add_vline(x=1.5, line_dash="dash", line_color="red", line_width=2,
                  annotation_text="PF=1.0 ç›ˆè™§åˆ†ç•Œç·š", annotation_position="top")
    
    fig.update_layout(
        title='ç²åˆ©å› å­åˆ†å¸ƒ (Profit Factor Distribution)',
        xaxis_title='Profit Factor å€é–“',
        yaxis_title='äº¤æ˜“è€…æ•¸é‡',
        height=500
    )
    
    profitable_ratio = (pf_data['Profit_Factor'] > 1.0).sum() / len(pf_data) * 100
    
    return fig, profitable_ratio, pf_data


def create_risk_return_scatter(df, initial_balance=0):
    """
    å‰µå»ºé¢¨éšªå›å ±çŸ©é™£æ•£ä½ˆåœ–ï¼ˆå‘é‡åŒ–é‡æ§‹ï¼‰
    
    ä½¿ç”¨ get_client_metrics æ›¿ä»£é€ç­†è¿´åœˆ
    """
    aid_col = COLUMN_MAP['aid']
    volume_col = COLUMN_MAP['volume']
    
    df = df.copy()
    df[aid_col] = df[aid_col].astype(str)
    
    # ä½¿ç”¨å‘é‡åŒ–çš„å®¢æˆ¶æŒ‡æ¨™è¨ˆç®—
    metrics = get_client_metrics(df, initial_balance)
    
    if metrics.empty:
        return go.Figure(), pd.DataFrame()
    
    # è¨ˆç®—äº¤æ˜“é‡
    if volume_col in df.columns:
        volume_agg = df.groupby(aid_col, as_index=False)[volume_col].sum()
        volume_agg.columns = [aid_col, 'Trade_Volume']
    else:
        volume_agg = df.groupby(aid_col, as_index=False).size()
        volume_agg.columns = [aid_col, 'Trade_Volume']
    
    scatter_df = metrics.merge(volume_agg, on=aid_col, how='left')
    scatter_df = scatter_df.rename(columns={'Total_PL': 'Net_PL'})
    
    # ç¢ºä¿ AID ç‚ºå­—ä¸²
    scatter_df['AID'] = scatter_df[aid_col].astype(str)
    
    # æ¨™æº–åŒ–é»å¤§å°
    min_size, max_size = 10, 50
    vol_min, vol_max = scatter_df['Trade_Volume'].min(), scatter_df['Trade_Volume'].max()
    if vol_max > vol_min:
        scatter_df['Size'] = min_size + (scatter_df['Trade_Volume'] - vol_min) / (vol_max - vol_min) * (max_size - min_size)
    else:
        scatter_df['Size'] = 20
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=scatter_df['MDD_Pct'],
        y=scatter_df['Net_PL'],
        mode='markers',
        marker=dict(
            size=scatter_df['Size'],
            color=scatter_df['Net_PL'],
            colorscale=['#E74C3C', '#F39C12', '#27AE60'],
            showscale=True,
            colorbar=dict(title='Net P/L')
        ),
        customdata=np.column_stack((
            scatter_df['AID'],
            scatter_df['Trade_Volume'],
            scatter_df['Trade_Count']
        )),
        hovertemplate=(
            '<b>AID:</b> %{customdata[0]}<br>'
            '<b>æ·¨ç›ˆè™§:</b> $%{y:,.2f}<br>'
            '<b>MDD:</b> %{x:.2f}%<br>'
            '<b>äº¤æ˜“é‡:</b> %{customdata[1]:,.0f}<br>'
            '<b>äº¤æ˜“ç­†æ•¸:</b> %{customdata[2]}<extra></extra>'
        ),
        name='äº¤æ˜“è€…'
    ))
    
    fig.update_layout(
        title=f'é¢¨éšªå›å ±çŸ©é™£ (Risk-Return Matrix) - åˆå§‹è³‡é‡‘: ${initial_balance:,.0f}',
        xaxis_title='æœ€å¤§å›æ’¤ MDD (%)',
        yaxis_title='æœˆåº¦æ·¨ç›ˆè™§ (Net P/L)',
        height=600
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
    
    fig.add_annotation(x=0.05, y=0.95, xref="paper", yref="paper", text="ğŸŒŸ æ˜æ˜Ÿäº¤æ˜“å“¡", showarrow=False, font=dict(size=12, color="green"))
    fig.add_annotation(x=0.95, y=0.95, xref="paper", yref="paper", text="âš¡ æ¿€é€²å‹", showarrow=False, font=dict(size=12, color="orange"))
    fig.add_annotation(x=0.05, y=0.05, xref="paper", yref="paper", text="ğŸ¢ å®ˆèˆŠå‹", showarrow=False, font=dict(size=12, color="gray"))
    fig.add_annotation(x=0.95, y=0.05, xref="paper", yref="paper", text="âš ï¸ é«˜é¢¨éšª", showarrow=False, font=dict(size=12, color="red"))
    
    return fig, scatter_df


def create_hold_time_analysis(df, scalper_threshold_seconds=300):
    """å‰µå»ºæŒå€‰æ™‚é–“ vs å‹ç‡é—œè¯åˆ†æ"""
    aid_col = COLUMN_MAP['aid']
    scalp_minutes = scalper_threshold_seconds / 60
    
    df_analysis = df.copy()
    
    # å‘é‡åŒ–åˆ†é¡æŒå€‰æ™‚é–“
    conditions = [
        df_analysis['Hold_Seconds'] < scalper_threshold_seconds,
        df_analysis['Hold_Seconds'] < 3600,
        df_analysis['Hold_Seconds'] < 86400,
        df_analysis['Hold_Seconds'] >= 86400
    ]
    choices = [f'Scalp (<{scalp_minutes:.0f}m)', 'Short (<1h)', 'Intraday (<24h)', 'Swing (>1d)']
    
    df_analysis['Hold_Category'] = np.select(conditions, choices, default=None)
    df_analysis = df_analysis[df_analysis['Hold_Category'].notna()].copy()
    
    if df_analysis.empty:
        return None, None
    
    # å‘é‡åŒ–è¨ˆç®—å‹ç‡
    df_analysis['_is_win'] = (df_analysis['Net_PL'] > 0).astype(int)
    
    category_stats = df_analysis.groupby('Hold_Category', as_index=False).agg(
        äº¤æ˜“ç­†æ•¸=('Net_PL', 'count'),
        ç¸½ç›ˆè™§=('Net_PL', 'sum'),
        å¹³å‡ç›ˆè™§=('Net_PL', 'mean'),
        _wins=('_is_win', 'sum')
    )
    category_stats['å‹ç‡(%)'] = (category_stats['_wins'] / category_stats['äº¤æ˜“ç­†æ•¸'] * 100).round(2)
    category_stats = category_stats.drop(columns=['_wins'])
    category_stats.columns = ['æŒå€‰é¡å‹', 'äº¤æ˜“ç­†æ•¸', 'ç¸½ç›ˆè™§', 'å¹³å‡ç›ˆè™§', 'å‹ç‡(%)']
    
    order = [f'Scalp (<{scalp_minutes:.0f}m)', 'Short (<1h)', 'Intraday (<24h)', 'Swing (>1d)']
    category_stats['æŒå€‰é¡å‹'] = pd.Categorical(category_stats['æŒå€‰é¡å‹'], categories=order, ordered=True)
    category_stats = category_stats.sort_values('æŒå€‰é¡å‹')
    
    # å‰µå»ºæ•£ä½ˆåœ–
    df_analysis['Hold_Seconds_Log'] = np.log10(df_analysis['Hold_Seconds'].clip(lower=1))
    df_analysis['Color'] = np.where(df_analysis['Net_PL'] > 0, 'Profit', 'Loss')
    
    fig = px.scatter(
        df_analysis,
        x='Hold_Seconds_Log',
        y='Net_PL',
        color='Color',
        color_discrete_map={'Profit': '#27AE60', 'Loss': '#E74C3C'},
        opacity=0.6,
        title=f'æŒå€‰æ™‚é–“ vs å–®ç­†ç›ˆè™§ (Scalp å®šç¾©: <{scalp_minutes:.0f}åˆ†é˜)'
    )
    
    fig.add_vline(x=np.log10(scalper_threshold_seconds), line_dash="dash", line_color="red", line_width=2,
                  annotation_text=f"Scalp é–¾å€¼ ({scalp_minutes:.0f}åˆ†é˜)")
    fig.add_vline(x=np.log10(3600), line_dash="dash", line_color="gray", annotation_text="1å°æ™‚")
    fig.add_vline(x=np.log10(86400), line_dash="dash", line_color="gray", annotation_text="24å°æ™‚")
    
    fig.update_layout(xaxis_title='æŒå€‰æ™‚é–“ (Log10 ç§’)', yaxis_title='å–®ç­†ç›ˆè™§ (Net P/L)', height=500)
    
    return fig, category_stats


def create_daily_pnl_chart(df):
    """å‰µå»ºæ¯æ—¥ç›ˆè™§æŸ±ç‹€åœ–"""
    exec_col = COLUMN_MAP['execution_time']
    
    df_daily = df.copy()
    df_daily['Date'] = df_daily[exec_col].dt.date
    
    daily_pnl = df_daily.groupby('Date', as_index=False)['Net_PL'].sum()
    daily_pnl.columns = ['æ—¥æœŸ', 'æ¯æ—¥ç›ˆè™§']
    
    colors = ['#27AE60' if x > 0 else '#E74C3C' for x in daily_pnl['æ¯æ—¥ç›ˆè™§']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=daily_pnl['æ—¥æœŸ'],
        y=daily_pnl['æ¯æ—¥ç›ˆè™§'],
        marker_color=colors,
        name='æ¯æ—¥ç›ˆè™§'
    ))
    
    fig.add_hline(y=0, line_color="black", line_width=1)
    
    fig.update_layout(
        title='30å¤©æ¯æ—¥ç›ˆè™§åˆ†å¸ƒ',
        xaxis_title='æ—¥æœŸ',
        yaxis_title='æ·¨ç›ˆè™§',
        height=400
    )
    
    return fig


# ==================== å°å‡ºåŠŸèƒ½ ====================

def export_to_excel(df, initial_balance=10000, scalper_threshold_seconds=300):
    """å°å‡ºå®Œæ•´åˆ†ææ•¸æ“šåˆ° Excelï¼ˆå¤šåˆ†é ï¼‰"""
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    
    output = BytesIO()
    
    closing_df = filter_closing_trades(df)
    
    aid_col = COLUMN_MAP['aid']
    volume_col = COLUMN_MAP['volume']
    exec_col = COLUMN_MAP['execution_time']
    instrument_col = COLUMN_MAP['instrument']
    
    # ========== Sheet 1: æ•¸æ“šæ‘˜è¦ ==========
    total_trades = len(df)
    closing_trades = len(closing_df)
    unique_clients = df[aid_col].nunique()
    total_net_pl = closing_df['Net_PL'].sum()
    avg_net_pl = closing_df['Net_PL'].mean() if len(closing_df) > 0 else 0
    
    profitable_trades = (closing_df['Net_PL'] > 0).sum()
    losing_trades = (closing_df['Net_PL'] < 0).sum()
    win_rate = (profitable_trades / len(closing_df) * 100) if len(closing_df) > 0 else 0
    
    client_pl = closing_df.groupby(aid_col)['Net_PL'].sum()
    profitable_clients = (client_pl > 0).sum()
    losing_clients = (client_pl < 0).sum()
    
    scalper_trades = closing_df[closing_df['Hold_Seconds'] < scalper_threshold_seconds]
    scalper_count = scalper_trades[aid_col].nunique() if not scalper_trades.empty else 0
    scalper_pl = scalper_trades['Net_PL'].sum() if not scalper_trades.empty else 0
    
    summary_data = [
        ['æŒ‡æ¨™', 'æ•¸å€¼', 'èªªæ˜'],
        ['ç¸½äº¤æ˜“ç­†æ•¸', total_trades, 'æ‰€æœ‰äº¤æ˜“è¨˜éŒ„'],
        ['å¹³å€‰äº¤æ˜“ç­†æ•¸', closing_trades, 'CLOSING é¡å‹äº¤æ˜“'],
        ['ç¸½å®¢æˆ¶æ•¸', unique_clients, 'ä¸é‡è¤‡çš„ AID æ•¸é‡'],
        ['ç¸½æ·¨ç›ˆè™§', round(total_net_pl, 2), 'Net_PL = Closed P/L + Commission + Swap'],
        ['å¹³å‡å–®ç­†ç›ˆè™§', round(avg_net_pl, 2), 'å¹³å€‰äº¤æ˜“çš„å¹³å‡ Net_PL'],
        ['', '', ''],
        ['ç›ˆåˆ©äº¤æ˜“ç­†æ•¸', profitable_trades, 'Net_PL > 0'],
        ['è™§æäº¤æ˜“ç­†æ•¸', losing_trades, 'Net_PL < 0'],
        ['æ•´é«”å‹ç‡(%)', round(win_rate, 2), 'ç›ˆåˆ©äº¤æ˜“ä½”æ¯”'],
        ['', '', ''],
        ['ç›ˆåˆ©å®¢æˆ¶æ•¸', profitable_clients, 'ç´¯è¨ˆ Net_PL > 0'],
        ['è™§æå®¢æˆ¶æ•¸', losing_clients, 'ç´¯è¨ˆ Net_PL < 0'],
        ['å®¢æˆ¶ç›ˆåˆ©æ¯”(%)', round(profitable_clients / unique_clients * 100, 2) if unique_clients > 0 else 0, 'ç›ˆåˆ©å®¢æˆ¶ä½”æ¯”'],
        ['', '', ''],
        [f'Scalper æ•¸é‡ (<{scalper_threshold_seconds/60:.0f}åˆ†é˜)', scalper_count, 'çŸ­ç·šäº¤æ˜“è€…'],
        ['Scalper ç¸½ç›ˆè™§', round(scalper_pl, 2), 'Scalper äº¤æ˜“çš„ç´¯è¨ˆ Net_PL'],
        ['', '', ''],
        ['åˆå§‹è³‡é‡‘è¨­å®š', initial_balance, 'ç”¨æ–¼ MDD è¨ˆç®—'],
        ['Scalper é–¾å€¼(ç§’)', scalper_threshold_seconds, 'æŒå€‰æ™‚é–“é–¾å€¼'],
        ['å ±å‘Šç”Ÿæˆæ™‚é–“', datetime.now().strftime('%Y-%m-%d %H:%M:%S'), '']
    ]
    
    summary_df = pd.DataFrame(summary_data[1:], columns=summary_data[0])
    
    # ========== Sheet 2: é¢¨éšªå›å ±æ¸…å–®ï¼ˆä½¿ç”¨å‘é‡åŒ–ï¼‰==========
    metrics = get_client_metrics(closing_df, initial_balance, scalper_threshold_seconds)
    
    if not metrics.empty:
        # æ·»åŠ é¡å¤–æ¬„ä½
        if volume_col in closing_df.columns:
            volume_agg = closing_df.groupby(aid_col, as_index=False)[volume_col].sum()
            volume_agg.columns = [aid_col, 'Trade_Volume']
            metrics = metrics.merge(volume_agg, on=aid_col, how='left')
        
        # è¨ˆç®—å¹³å‡æŒå€‰æ™‚é–“
        hold_agg = closing_df.groupby(aid_col, as_index=False)['Hold_Seconds'].mean()
        hold_agg.columns = [aid_col, 'Avg_Hold_Seconds']
        hold_agg['Avg_Hold_Minutes'] = (hold_agg['Avg_Hold_Seconds'] / 60).round(2)
        metrics = metrics.merge(hold_agg[[aid_col, 'Avg_Hold_Minutes']], on=aid_col, how='left')
        
        # æ˜¯å¦ç‚º Scalper
        metrics['Is_Scalper'] = np.where(metrics['Scalp_Pct'] > 50, 'Yes', 'No')
        
        risk_return_df = metrics.rename(columns={
            aid_col: 'AID',
            'Total_PL': 'Net_PL',
            'MDD_Pct': 'MDD(%)',
            'Win_Rate': 'Win_Rate(%)',
            'Scalp_Pct': 'Scalper_Ratio(%)'
        })
        risk_return_df = risk_return_df.sort_values('Net_PL', ascending=False)
    else:
        risk_return_df = pd.DataFrame()
    
    # ========== Sheet 3: Scalper æ¸…å–® ==========
    scalper_df = closing_df[closing_df['Hold_Seconds'] < scalper_threshold_seconds].copy()
    
    if not scalper_df.empty:
        scalper_export_cols = [
            aid_col, exec_col, COLUMN_MAP['open_time'],
            instrument_col, COLUMN_MAP['side'], volume_col,
            COLUMN_MAP['closed_pl'], COLUMN_MAP['commission'], COLUMN_MAP['swap'],
            'Net_PL', 'Hold_Seconds'
        ]
        
        existing_cols = [col for col in scalper_export_cols if col in scalper_df.columns]
        scalper_export_df = scalper_df[existing_cols].copy()
        scalper_export_df['Hold_Minutes'] = (scalper_export_df['Hold_Seconds'] / 60).round(2)
        
        if exec_col in scalper_export_df.columns:
            scalper_export_df = scalper_export_df.sort_values(exec_col, ascending=False)
    else:
        scalper_export_df = pd.DataFrame({'è¨Šæ¯': ['ç„¡ç¬¦åˆæ¢ä»¶çš„ Scalper äº¤æ˜“è¨˜éŒ„']})
    
    # ========== å¯«å…¥ Excel ==========
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        summary_df.to_excel(writer, sheet_name='æ•¸æ“šæ‘˜è¦', index=False)
        if not risk_return_df.empty:
            risk_return_df.to_excel(writer, sheet_name='é¢¨éšªå›å ±æ¸…å–®', index=False)
        scalper_export_df.to_excel(writer, sheet_name='Scalperæ¸…å–®', index=False)
        
        # æ ¼å¼åŒ–
        workbook = writer.book
        header_font = Font(bold=True, color='FFFFFF')
        header_fill = PatternFill(start_color='2E86AB', end_color='2E86AB', fill_type='solid')
        thin_border = Border(
            left=Side(style='thin'), right=Side(style='thin'),
            top=Side(style='thin'), bottom=Side(style='thin')
        )
        
        for sheet_name in writer.sheets:
            ws = writer.sheets[sheet_name]
            
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = Alignment(horizontal='center')
                cell.border = thin_border
    
    output.seek(0)
    return output


# ==================== ä¸»ç¨‹å¼ ====================

def main():
    st.title("ğŸ“Š äº¤æ˜“æ•¸æ“šåˆ†æç³»çµ±")
    st.markdown("**æ”¯æŒå¤§è¦æ¨¡äº¤æ˜“æ•¸æ“šï¼ˆåè¬ç­†ä»¥ä¸Šï¼‰çš„è™•ç†èˆ‡åˆ†æ** | *ç¬¬ä¸€éšæ®µé‡æ§‹ï¼šæ ¸å¿ƒæ•¸æ“šå¼•æ“*")
    
    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("ğŸ“ æ•¸æ“šä¸Šå‚³")
        uploaded_files = st.file_uploader(
            "ä¸Šå‚³äº¤æ˜“æ•¸æ“šæª”æ¡ˆ (.xlsx æˆ– .csv)",
            type=['xlsx', 'csv'],
            accept_multiple_files=True
        )
        
        st.header("âš™ï¸ åƒæ•¸è¨­å®š")
        
        initial_balance = st.number_input(
            "åˆå§‹è³‡é‡‘ (ç”¨æ–¼ MDD è¨ˆç®—)",
            value=10000, min_value=0, step=1000,
            help="è¨­å®šæ¯ä½äº¤æ˜“è€…çš„åˆå§‹è³‡é‡‘"
        )
        
        scalper_minutes = st.number_input(
            "Scalper æŒå€‰æ™‚é–“å®šç¾© (åˆ†é˜)",
            value=5, min_value=1, max_value=60, step=1,
            help="æŒå€‰æ™‚é–“å°æ–¼æ­¤å€¼çš„äº¤æ˜“å°‡è¢«æ­¸é¡ç‚º Scalp äº¤æ˜“"
        )
        
        scalper_threshold_seconds = scalper_minutes * 60
        
        if uploaded_files:
            st.success(f"å·²ä¸Šå‚³ {len(uploaded_files)} å€‹æª”æ¡ˆ")
            st.markdown("---")
            st.info(f"ğŸ’° åˆå§‹è³‡é‡‘: **${initial_balance:,}**")
            st.info(f"â±ï¸ Scalper å®šç¾©: **<{scalper_minutes} åˆ†é˜**")
            
            st.markdown("---")
            st.header("ğŸ“¥ å°å‡ºå ±è¡¨")
            
            @st.cache_data(show_spinner=False)
            def generate_excel_report(_df, init_bal, scalp_thresh):
                return export_to_excel(_df, init_bal, scalp_thresh)
            
            df_for_export = load_data(uploaded_files)
            
            if df_for_export is not None:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå ±è¡¨..."):
                    excel_data = generate_excel_report(df_for_export, initial_balance, scalper_threshold_seconds)
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è¼‰å®Œæ•´åˆ†ææ•¸æ“š (.xlsx)",
                    data=excel_data,
                    file_name=f"trading_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    help="åŒ…å«ä¸‰å€‹åˆ†é ï¼šæ•¸æ“šæ‘˜è¦ã€é¢¨éšªå›å ±æ¸…å–®ã€Scalper æ¸…å–®"
                )
    
    if not uploaded_files:
        st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´ä¸Šå‚³äº¤æ˜“æ•¸æ“šæª”æ¡ˆé–‹å§‹åˆ†æ")
        
        st.markdown("""
        ### ğŸ“‹ åŠŸèƒ½èªªæ˜
        
        **ç¬¬ä¸€éƒ¨åˆ†ï¼šç•¶æ—¥åˆ†æ (Daily Analysis)**
        - Top 10 Profit å®¢æˆ¶
        - Top 10 Scalpersï¼ˆçŸ­ç·šäº¤æ˜“è€…ï¼‰
        
        **ç¬¬äºŒéƒ¨åˆ†ï¼š30å¤©åˆ†æ (30-Day Analysis)**
        1. ç´¯è¨ˆç›ˆè™§èµ°å‹¢åœ–
        2. å®¢æˆ¶ç›ˆè™§åˆ†å¸ƒåœ– (Violin Plot)
        3. ç²åˆ©å› å­åˆ†å¸ƒåœ– (PF Distribution)
        4. é¢¨éšªå›å ±çŸ©é™£ (Risk-Return Scatter)
        5. æŒå€‰ vs å‹ç‡é—œè¯åˆ†æ
        6. æ¯æ—¥ç›ˆè™§æŸ±ç‹€åœ–
        
        **ğŸš€ ç¬¬ä¸€éšæ®µé‡æ§‹ç‰¹æ€§ï¼š**
        - âœ… é«˜æ•ˆå¿«å–æ©Ÿåˆ¶ (`@st.cache_data`)
        - âœ… å‘é‡åŒ–é‹ç®—ï¼ˆç¦æ­¢ apply/loopï¼‰
        - âœ… AID å¼·åˆ¶å­—ä¸²åŒ–ï¼ˆè§£æ±ºè¤‡è£½å¤±æ•ˆï¼‰
        - âœ… å¤§æ•¸æ“šæ¡æ¨£å„ªåŒ–ï¼ˆViolin Plotï¼‰
        """)
        return
    
    # è¼‰å…¥æ•¸æ“š
    with st.spinner("æ­£åœ¨è¼‰å…¥å’Œè™•ç†æ•¸æ“š..."):
        df = load_data(uploaded_files)
    
    if df is None or df.empty:
        st.error("ç„¡æ³•è¼‰å…¥æ•¸æ“šï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼")
        return
    
    # é¡¯ç¤ºæ•¸æ“šæ‘˜è¦
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    
    closing_df = filter_closing_trades(df)
    
    with col1:
        st.metric("ç¸½äº¤æ˜“ç­†æ•¸", f"{len(df):,}")
    with col2:
        st.metric("å¹³å€‰äº¤æ˜“ç­†æ•¸", f"{len(closing_df):,}")
    with col3:
        st.metric("äº¤æ˜“è€…æ•¸é‡", f"{df[COLUMN_MAP['aid']].nunique():,}")
    with col4:
        total_pnl = closing_df['Net_PL'].sum()
        st.metric("ç¸½æ·¨ç›ˆè™§", f"${total_pnl:,.2f}")
    
    # ==================== ç¬¬ä¸€éƒ¨åˆ†ï¼šç•¶æ—¥åˆ†æ ====================
    st.markdown("---")
    st.header("ğŸ“… ç¬¬ä¸€éƒ¨åˆ†ï¼šç•¶æ—¥åˆ†æ (Daily Analysis)")
    
    daily_result = get_daily_analysis(df, scalper_threshold_seconds)
    
    if daily_result and daily_result[0] is not None:
        top_profit, top_scalpers, latest_date = daily_result
        
        st.subheader(f"ğŸ“† åˆ†ææ—¥æœŸ: {latest_date}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ† Top 10 Profit å®¢æˆ¶")
            if not top_profit.empty:
                st.dataframe(top_profit, use_container_width=True, hide_index=True)
            else:
                st.info("ç•¶æ—¥ç„¡ç›ˆåˆ©æ•¸æ“š")
        
        with col2:
            st.markdown(f"### âš¡ Top 10 Scalpers (å®šç¾©: æŒå€‰ <{scalper_minutes} åˆ†é˜)")
            if not top_scalpers.empty:
                st.dataframe(top_scalpers, use_container_width=True, hide_index=True)
            else:
                st.info(f"ç•¶æ—¥ç„¡æŒå€‰ <{scalper_minutes} åˆ†é˜çš„çŸ­ç·šäº¤æ˜“æ•¸æ“š")
    else:
        st.warning("ç„¡æ³•å–å¾—ç•¶æ—¥åˆ†ææ•¸æ“š")
    
    # ==================== ç¬¬äºŒéƒ¨åˆ†ï¼š30å¤©åˆ†æ ====================
    st.markdown("---")
    st.header("ğŸ“Š ç¬¬äºŒéƒ¨åˆ†ï¼š30å¤©åˆ†æ (30-Day Analysis)")
    
    result_30d = get_30day_analysis(df)
    
    if result_30d:
        df_30d, start_date, end_date = result_30d
        
        st.subheader(f"ğŸ“† åˆ†ææœŸé–“: {start_date.date()} ~ {end_date.date()}")
        
        # 30å¤© Top 10 åˆ—è¡¨
        col1, col2 = st.columns(2)
        
        aid_col = COLUMN_MAP['aid']
        instrument_col = COLUMN_MAP['instrument']
        
        with col1:
            st.markdown("### ğŸ† 30å¤© Top 10 Profit å®¢æˆ¶")
            top_30d_profit = df_30d.groupby(aid_col)['Net_PL'].sum().nlargest(10).reset_index()
            top_30d_profit.columns = ['AID', '30å¤©ç¸½ç›ˆè™§']
            top_30d_profit['AID'] = top_30d_profit['AID'].astype(str)
            st.dataframe(top_30d_profit, use_container_width=True, hide_index=True)
        
        with col2:
            st.markdown(f"### âš¡ 30å¤© Top 10 Scalpers (å®šç¾©: æŒå€‰ <{scalper_minutes} åˆ†é˜)")
            scalp_30d = df_30d[df_30d['Hold_Seconds'] < scalper_threshold_seconds]
            if not scalp_30d.empty:
                scalper_30d = scalp_30d.groupby(aid_col, as_index=False).agg(
                    äº¤æ˜“ç­†æ•¸=('Net_PL', 'count'),
                    ç¸½ç›ˆè™§=('Net_PL', 'sum'),
                    å¹³å‡æŒå€‰ç§’æ•¸=('Hold_Seconds', 'mean')
                )
                scalper_30d.columns = ['AID', 'äº¤æ˜“ç­†æ•¸', 'ç¸½ç›ˆè™§', 'å¹³å‡æŒå€‰ç§’æ•¸']
                scalper_30d = scalper_30d.nlargest(10, 'äº¤æ˜“ç­†æ•¸')
                scalper_30d['AID'] = scalper_30d['AID'].astype(str)
                scalper_30d['å¹³å‡æŒå€‰ç§’æ•¸'] = scalper_30d['å¹³å‡æŒå€‰ç§’æ•¸'].round(1)
                st.dataframe(scalper_30d, use_container_width=True, hide_index=True)
            else:
                st.info(f"ç„¡æŒå€‰ <{scalper_minutes} åˆ†é˜çš„çŸ­ç·šäº¤æ˜“æ•¸æ“š")
        
        st.markdown("---")
        
        # 1. ç´¯è¨ˆæ·¨ç›ˆè™§èµ°å‹¢åœ–
        st.markdown("### ğŸ“ˆ 1. 30å¤©ç´¯è¨ˆæ·¨ç›ˆè™§èµ°å‹¢")
        
        cumulative_fig, pnl_stats = create_cumulative_pnl_chart(df_30d, initial_balance, scalper_threshold_seconds)
        st.plotly_chart(cumulative_fig, use_container_width=True)
        
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        with col_stat1:
            st.metric("æ•´é«”æ·¨ç›ˆè™§", f"${pnl_stats['total_pnl']:,.2f}")
        with col_stat2:
            st.metric(f"Scalper æ·¨ç›ˆè™§ (<{scalper_minutes}åˆ†é˜)", f"${pnl_stats['scalper_pnl']:,.2f}",
                     delta=f"{pnl_stats['scalper_ratio']:.1f}% ä½”æ¯”")
        with col_stat3:
            st.metric("é Scalper æ·¨ç›ˆè™§", f"${pnl_stats['non_scalper_pnl']:,.2f}")
        
        st.markdown("---")
        
        # 2. å°æç´åœ– (Violin Plot)
        st.markdown("### ğŸ» 2. å®¢æˆ¶ç›ˆè™§åˆ†å¸ƒåœ– (Violin Plot)")
        
        col_filter1, col_filter2 = st.columns([1, 2])
        with col_filter1:
            filter_extreme = st.checkbox(
                "éš±è—æ¥µç«¯é›¢ç¾¤å€¼ (1%-99%)", 
                value=True,
                help="å‹¾é¸å¾Œå°‡éæ¿¾æ‰æœ€æ¥µç«¯çš„ 1% é«˜å€¼å’Œ 1% ä½å€¼"
            )
        
        violin_fig, pos_outliers, neg_outliers, filter_info = create_violin_plot(df_30d, filter_extreme)
        st.plotly_chart(violin_fig, use_container_width=True)
        
        # é¡¯ç¤ºéæ¿¾å’Œæ¡æ¨£è³‡è¨Š
        info_messages = []
        if filter_extreme and filter_info['filtered_count'] > 0:
            info_messages.append(f"å·²éæ¿¾ {filter_info['filtered_count']} ä½æ¥µç«¯å®¢æˆ¶")
        if filter_info.get('sampling_info', {}).get('sampled'):
            info_messages.append(f"å·²å¾ {filter_info['sampling_info']['original_count']:,} ä½å®¢æˆ¶æ¡æ¨£ {filter_info['sampling_info']['sampled_count']:,} ä½")
        
        if info_messages:
            st.info(f"ğŸ“Š {' | '.join(info_messages)}")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ”´ Top 5 Positive Outliers (æš´åˆ©)")
            if not pos_outliers.empty:
                pos_outliers['AID'] = pos_outliers['AID'].astype(str)
                st.dataframe(pos_outliers, use_container_width=True, hide_index=True)
            else:
                st.info("ç„¡æ­£å‘ç•°å¸¸å€¼")
        
        with col2:
            st.markdown("#### ğŸ”µ Top 5 Negative Outliers (æš´æ)")
            if not neg_outliers.empty:
                neg_outliers['AID'] = neg_outliers['AID'].astype(str)
                st.dataframe(neg_outliers, use_container_width=True, hide_index=True)
            else:
                st.info("ç„¡è² å‘ç•°å¸¸å€¼")
        
        st.markdown("---")
        
        # 3. ç²åˆ©å› å­åˆ†å¸ƒåœ–
        st.markdown("### ğŸ“Š 3. ç²åˆ©å› å­åˆ†å¸ƒ (Profit Factor)")
        
        pf_fig, profitable_ratio, pf_data = create_profit_factor_chart(df_30d)
        st.plotly_chart(pf_fig, use_container_width=True)
        st.success(f"ğŸ“ˆ **30å¤©å…§ PF > 1.0 çš„äº¤æ˜“è€…ä½”æ¯”: {profitable_ratio:.1f}%** (è³ºéŒ¢çš„äºº)")
        
        st.markdown("---")
        
        # 4. é¢¨éšªå›å ±çŸ©é™£
        st.markdown("### ğŸ¯ 4. é¢¨éšªå›å ±çŸ©é™£ (Risk-Return Matrix)")
        
        scatter_fig, scatter_data = create_risk_return_scatter(df_30d, initial_balance)
        st.plotly_chart(scatter_fig, use_container_width=True)
        
        st.markdown("""
        **è±¡é™èªªæ˜ï¼š**
        - ğŸŒŸ **å·¦ä¸Š (Low MDD, High P/L)**: æ˜æ˜Ÿäº¤æ˜“å“¡
        - âš¡ **å³ä¸Š (High MDD, High P/L)**: æ¿€é€²å‹äº¤æ˜“å“¡
        - ğŸ¢ **å·¦ä¸‹ (Low MDD, Low P/L)**: å®ˆèˆŠå‹äº¤æ˜“å“¡
        - âš ï¸ **å³ä¸‹ (High MDD, Low P/L)**: é«˜é¢¨éšªäº¤æ˜“å“¡
        """)
        
        with st.expander("ğŸ“‹ æŸ¥çœ‹é¢¨éšªå›å ±è©³ç´°æ•¸æ“š"):
            if not scatter_data.empty:
                display_data = scatter_data[['AID', 'Net_PL', 'MDD_Pct', 'Trade_Volume', 'Trade_Count']].copy()
                display_data['AID'] = display_data['AID'].astype(str)
                display_data.columns = ['AID', 'æ·¨ç›ˆè™§', 'MDD (%)', 'äº¤æ˜“é‡', 'äº¤æ˜“ç­†æ•¸']
                display_data['æ·¨ç›ˆè™§'] = display_data['æ·¨ç›ˆè™§'].apply(lambda x: f"${x:,.2f}")
                display_data['MDD (%)'] = display_data['MDD (%)'].apply(lambda x: f"{x:.2f}%")
                st.dataframe(display_data, use_container_width=True, hide_index=True)
                st.caption(f"ğŸ’¡ MDD è¨ˆç®—åŸºæ–¼åˆå§‹è³‡é‡‘ ${initial_balance:,}")
        
        st.markdown("---")
        
        # 5. æŒå€‰æ™‚é–“ vs å‹ç‡åˆ†æ
        st.markdown(f"### â±ï¸ 5. æŒå€‰æ™‚é–“ vs å‹ç‡é—œè¯åˆ†æ (Scalp å®šç¾©: <{scalper_minutes} åˆ†é˜)")
        
        hold_fig, hold_stats = create_hold_time_analysis(df_30d, scalper_threshold_seconds)
        
        if hold_fig is not None:
            st.plotly_chart(hold_fig, use_container_width=True)
            st.markdown("#### å„æŒå€‰é¡å‹çµ±è¨ˆ")
            st.dataframe(hold_stats, use_container_width=True, hide_index=True)
        else:
            st.warning("ç„¡æŒå€‰æ™‚é–“æ•¸æ“šå¯ä¾›åˆ†æ")
        
        st.markdown("---")
        
        # 6. æ¯æ—¥ç›ˆè™§æŸ±ç‹€åœ–
        st.markdown("### ğŸ“… 6. æ¯æ—¥ç›ˆè™§æŸ±ç‹€åœ–")
        
        daily_fig = create_daily_pnl_chart(df_30d)
        st.plotly_chart(daily_fig, use_container_width=True)
    
    else:
        st.warning("ç„¡æ³•å–å¾— 30 å¤©åˆ†ææ•¸æ“š")
    
    # ==================== å°å‡ºåŠŸèƒ½ï¼ˆåº•éƒ¨å‚™ç”¨å…¥å£ï¼‰====================
    st.markdown("---")
    st.header("ğŸ“¥ æ•¸æ“šå°å‡º")
    
    st.info("ğŸ’¡ æ‚¨ä¹Ÿå¯ä»¥åœ¨å·¦å´é‚Šæ¬„ç›´æ¥é»æ“Šã€Œä¸‹è¼‰å®Œæ•´åˆ†ææ•¸æ“šã€æŒ‰éˆ•å°å‡ºå ±è¡¨ã€‚")
    
    col_export1, col_export2 = st.columns([2, 1])
    
    with col_export1:
        st.markdown("""
        **Excel å ±è¡¨å…§å®¹èªªæ˜ï¼š**
        - **Sheet 1 (æ•¸æ“šæ‘˜è¦)**: ç¸½å®¢æˆ¶æ•¸ã€ç¸½ç›ˆè™§ã€å¹³å‡ç›ˆè™§ã€å‹ç‡ç­‰åŸºæœ¬æŒ‡æ¨™
        - **Sheet 2 (é¢¨éšªå›å ±æ¸…å–®)**: æ‰€æœ‰ AID çš„ Net_PL, MDD%, Trade_Volume, Win_Rate ç­‰
        - **Sheet 3 (Scalper æ¸…å–®)**: ç¬¦åˆ Scalper å®šç¾©çš„äº¤æ˜“æ˜ç´°
        """)
    
    with col_export2:
        with st.spinner("æº–å‚™å ±è¡¨..."):
            excel_data = export_to_excel(df, initial_balance, scalper_threshold_seconds)
        
        st.download_button(
            label="ğŸ“Š ä¸‹è¼‰å®Œæ•´åˆ†ææ•¸æ“š (.xlsx)",
            data=excel_data,
            file_name=f"trading_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )


if __name__ == "__main__":
    main()
